---
title: "Homework 5"
author: "Ainsel Levitskaia-Collins, HL2710"
date: "2025-11-05"
output: github_document
---

```{r include = FALSE}
library(tidyverse)
```


### Problem 1

Function:

- [X] fixed group size
- [X] randomly draws "birthdays" for each person
- [X] checks whether there are duplicate birthdays in the group
- [X] returns `TRUE` or `FALSE` based on the result

```{r eval = FALSE}
#' repeat_birthdays
#'
#' @param group_size The size of the sample for which birthdays will be selected
#'
#' @returns A boolean value for whether or not there are any overlapping birthdays within the sample
repeat_birthdays = function(group_size) {
  birthday_df <- data.frame(birthdays = sample(1:365, size = group_size, replace = TRUE)) %>% 
    group_by(birthdays) %>% 
    count(birthdays) %>% 
    arrange(desc(n))
  
  overlap <- FALSE
  
  for (i in 1:ncol(birthday_df)) {
    if (pull(birthday_df, n)[[1]] > 1) {
      overlap = TRUE
    }
  }
  
  overlap
}

# write.table(sim_results_df, "./data/birthday_sim_results.txt", col.names = T, row.names = F, quote = F, sep = "\t")
```


Analysis:

- [ ] run above function 10,000 times for each group size between 2 and 50
- [ ] for each group size, compute the probability that at least two people in the group will share a birthday by averaging across the 10,000 simulation runs
- [ ] make a plot showing the probability as a function of group size
- [ ] comment on results

```{r eval = FALSE}
birthday_sim_df <-
  expand_grid(
    sample_size = 2:5,
    iter = 1:10
  ) %>% 
  mutate(
    estimate_df = map(sample_size, repeat_birthdays)
  ) %>% 
  unnest(estimate_df)
```



### Problem 2

Creating a function that generates results for the model $x \sim {\sf Normal}[\mu, \sigma]$ with a set *n* of 30:

```{r}
normal_sim = function(n = 30, mean, sd) {
  x_vec <- tibble(x = rnorm(n, mean, sd))
  
  x_vec
}
```

Creating a dataframe with 5,000 datasets for each value of $\mu$ = {0, 1, 2, 3, 4, 5, 6} and with a set standard deviation of 5:

```{r message = FALSE}
normal_sim_df <-
  expand_grid(
    mean = 0:6,
    sd = 5,
    iter = 1:5000) %>% 
  mutate(
    x = map2(mean, sd, \(mean, sd) normal_sim(mean = mean, sd = sd))
  ) %>% 
  unnest(x)
```

Extracting $\hat{\mu}$ for every iteration group:

```{r message = FALSE}
normal_sim_means <-
  normal_sim_df %>% 
  group_by(mean, iter) %>%  
  summarize(mean_hat = mean(x))
```

Running `t.test` with a significance level of 0.05 on every iteration group and producing an end dataframe that retains the original expected $\mu$ value while also containing `t.test` results:

```{r warning = FALSE, message = FALSE}
normal_sim_results <- normal_sim_df %>% 
  group_by(iter) %>% 
  summarise(
    mean_true = unique(mean),
    ttest = list(broom::tidy(t.test(x, conf.level = 0.95, mu = unique(mean)[1])))
  ) %>% 
  janitor::clean_names() %>% 
  unnest(ttest)
```

Adding the $\hat{\mu}$ values into the `t.test` results dataframe, and organizing the `normal_sim_results` structure:

```{r}
normal_sim_means <- normal_sim_means %>% rename(mean_true = mean)

normal_sim_results <- merge(normal_sim_results, normal_sim_means, by = c("mean_true", "iter"))

normal_sim_results <- normal_sim_results %>% 
  select(iter, mean_true, mean_hat, p.value, everything()) %>% 
  arrange(iter) %>% 
  arrange(mean_true)

head(normal_sim_results)
```


- [ ] make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of mean on the x axis
  - [ ] describe the association between effect size and power
- [ ] make a plot showing the average estimate of mean-hat on the y axis and the true value of mean on the x axis
- [ ] make a second plot, or overlay on the above, the average estimate of mean-hat *only in the samples for which the null was rejected* (ie significant samples) on the y axis and the true value of mean on the x axis
  - [ ] is the sample average of mean-hat across tests for which the null is rejected approximately equal to the true value of mean? why or why not?

### Problem 3
